# one-paper-a-week
Trying to read one paper a week.

- [Chain of Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)
- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf)
- [Automatic Summarization of Conversational Multi-Party Speech](https://www.aaai.org/Papers/AAAI/2006/AAAI06-335.pdf)
- [The NeBuLa RPC-Optimized Architecture](http://infoscience.epfl.ch/record/277391/files/The%20NeBuLa%20RPC-Optimized%20Architecture.pdf)
- [A Deep Reinforced Model for Abstractive Summarization](https://arxiv.org/pdf/1705.04304.pdf)
- [Attention Is All You Need](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)
  - https://medium.com/@joealato/attention-in-nlp-734c6fa9d983
  - http://colah.github.io/posts/2015-08-Understanding-LSTMs/
  - http://karpathy.github.io/2015/05/21/rnn-effectiveness/
